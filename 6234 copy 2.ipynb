{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jdatetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self):\n",
    "        self.url = None\n",
    "        self.df_title = None\n",
    "        self.df_location = None\n",
    "        self.df_date = None\n",
    "        self.buy_history = None\n",
    "        self.iter_history = None\n",
    "        self.interaction = None\n",
    "        self.merged_df = None\n",
    "        self.dfs = None\n",
    "        self.recommender = None\n",
    "        self.event_df = None\n",
    "\n",
    "    def data_scrap(self, url: str):\n",
    "        \"\"\"use site url to scrap necessary data\n",
    "\n",
    "        Args:\n",
    "            url (str): site address\n",
    "\n",
    "        \"\"\"\n",
    "        url = url\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            h3_tags_title = soup.find_all(\"h3\", class_=\"blog_post_title my-2\")\n",
    "            h3_tags_location = soup.find_all(\"div\", class_=\"blog_post_title my-2\")\n",
    "            h3_tags_date = soup.find_all(\"div\", class_=\"theater-date my-2\")\n",
    "\n",
    "            titles = []\n",
    "            location = []\n",
    "            date = []\n",
    "\n",
    "            for title in h3_tags_title:\n",
    "                if title.text.strip():\n",
    "                    titles.append(title.text.strip())\n",
    "\n",
    "            self.df_title = pd.DataFrame({\"Titles\": titles})\n",
    "            df_title = self.df_title\n",
    "\n",
    "            for loc in h3_tags_location:\n",
    "                if loc.text.strip():\n",
    "                    location.append(loc.text.strip())\n",
    "\n",
    "            self.df_location = pd.DataFrame({\"Titles\": location})\n",
    "            df_location = self.df_location\n",
    "\n",
    "            for dt in h3_tags_date:\n",
    "                if dt.text.strip():\n",
    "                    date.append(dt.text.strip())\n",
    "\n",
    "            self.df_date = pd.DataFrame({\"Titles\": date})\n",
    "            df_date = self.df_date\n",
    "\n",
    "            return df_title, df_location, df_date\n",
    "\n",
    "    def user_buy_interaction_from_api(self, buy_api: str, iter_api: str):\n",
    "        \"\"\"use api to scrap buy and interaction users\n",
    "\n",
    "        Args:\n",
    "            buy_api (str): api to scrape user buy history\n",
    "            iter_api (str): api to scrape user iter history\n",
    "        \"\"\"\n",
    "        pd.options.mode.copy_on_write = True\n",
    "        buy_link = buy_api\n",
    "        iter_link = iter_api\n",
    "\n",
    "        urllib.request.urlretrieve(iter_link, \"log.xlsx\")\n",
    "        self.iter_history = pd.read_excel(\"log.xlsx\")\n",
    "        iter_history = pd.read_excel(\"log.xlsx\")\n",
    "\n",
    "        urllib.request.urlretrieve(buy_link, \"visitor.xlsx\")\n",
    "        self.buy_history = pd.read_excel(\"visitor.xlsx\")\n",
    "        buy_history = pd.read_excel(\"visitor.xlsx\")\n",
    "\n",
    "        return iter_history, buy_history\n",
    "\n",
    "    def generate_date_ranges(self, start_date, end_date):\n",
    "        date_ranges = []\n",
    "        current_start_date = start_date\n",
    "        while current_start_date < end_date:\n",
    "            current_end_date = current_start_date + timedelta(days=60)\n",
    "            if current_end_date > end_date:\n",
    "                current_end_date = end_date\n",
    "            date_ranges.append((current_start_date, current_end_date))\n",
    "            current_start_date = current_end_date\n",
    "        return date_ranges\n",
    "\n",
    "    def fetch_data_from_api_log(self, start_date, end_date):\n",
    "        start_date = start_date.strftime(\"%Y/%m/%d\")\n",
    "        end_date = end_date.strftime(\"%Y/%m/%d\")\n",
    "        url = f\"https://6234.ir/api/log?token=aiapiqazxcvbnm1403&ofDate={start_date}&toDate={end_date}\"\n",
    "        urllib.request.urlretrieve(\n",
    "            url,\n",
    "            \"log.xlsx\",\n",
    "        )\n",
    "        # iter_history = pd.read_excel(\"log.xlsx\")\n",
    "\n",
    "        # return iter_history\n",
    "\n",
    "    def interaction_auto(self):\n",
    "        start_date_jalali = jdatetime.datetime.strptime(\n",
    "            jdatetime.date(1403, 1, 1).strftime(\"%Y/%m/%d\"), \"%Y/%m/%d\"\n",
    "        ).date()\n",
    "\n",
    "        end_date_jalali = jdatetime.datetime.strptime(\n",
    "            jdatetime.datetime.now().strftime(\"%Y/%m/%d\"), \"%Y/%m/%d\"\n",
    "        ).date()\n",
    "\n",
    "        date_ranges = self.generate_date_ranges(start_date_jalali, end_date_jalali)\n",
    "        all_data = {}\n",
    "\n",
    "        for start, end in date_ranges:\n",
    "            data = self.fetch_data_from_api_log(start, end)\n",
    "            all_data.update(data)\n",
    "            df_log = pd.DataFrame(all_data)\n",
    "\n",
    "        return df_log\n",
    "\n",
    "    def fetch_data_from_api_buy(self, start_date, end_date):\n",
    "        start_date = start_date.strftime(\"%Y/%m/%d\")\n",
    "        end_date = end_date.strftime(\"%Y/%m/%d\")\n",
    "        url = f\"https://6234.ir/api/ticket?token=aiapiqazxcvbnm1403&ofDate={start_date}&toDate={end_date}\"\n",
    "        urllib.request.urlretrieve(\n",
    "            url,\n",
    "            \"visitor.xlsx\",\n",
    "        )\n",
    "        buy_history = pd.read_excel(\"visitor.xlsx\")\n",
    "\n",
    "        return buy_history\n",
    "\n",
    "    def buy_auto(self):\n",
    "        start_date_jalali = jdatetime.datetime.strptime(\n",
    "            jdatetime.date(1403, 1, 1).strftime(\"%Y/%m/%d\"), \"%Y/%m/%d\"\n",
    "        ).date()\n",
    "\n",
    "        end_date_jalali = jdatetime.datetime.strptime(\n",
    "            jdatetime.datetime.now().strftime(\"%Y/%m/%d\"), \"%Y/%m/%d\"\n",
    "        ).date()\n",
    "\n",
    "        date_ranges = self.generate_date_ranges(start_date_jalali, end_date_jalali)\n",
    "        all_data = {}\n",
    "\n",
    "        for start, end in date_ranges:\n",
    "            data = self.fetch_data_from_api_buy(start, end)\n",
    "            all_data.update(data)\n",
    "            df_buy = pd.DataFrame(all_data)\n",
    "\n",
    "        return df_buy\n",
    "\n",
    "    def preprocessing_interaction(self, interaction_df: pd.DataFrame):\n",
    "        \"\"\"preprocessing interaction data for use in model\n",
    "\n",
    "        Args:\n",
    "            interaction_df (pd.DataFrame): interaction pd from user_buy_interaction_from_api func\n",
    "\n",
    "        Returns:\n",
    "            interaction_df (pd.DataFrame): interaction_df\n",
    "        \"\"\"\n",
    "        interaction_df[\"بازدید\"] = interaction_df[\"بازدید\"].fillna(\"ffill\")\n",
    "        interaction_df[\"نام و نام خانوادگی\"] = interaction_df[\n",
    "            \"نام و نام خانوادگی\"\n",
    "        ].fillna(\"none\")\n",
    "        interaction_df[\"شماره موبایل\"] = interaction_df[\"شماره موبایل\"].fillna(\"none\")\n",
    "        interaction_df = interaction_df[interaction_df[\"بازدید\"] != \"صفحه اصلی\"]\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        interaction_df.loc[:, \"userId\"] = le.fit_transform(\n",
    "            interaction_df[\"نام و نام خانوادگی\"]\n",
    "        )\n",
    "\n",
    "        return interaction_df\n",
    "\n",
    "    def event_api(self, api: str):\n",
    "        event_link = api\n",
    "\n",
    "        urllib.request.urlretrieve(event_link, \"event.xlsx\")\n",
    "        self.iter_history = pd.read_excel(\"event.xlsx\")\n",
    "        event_df = pd.read_excel(\"event.xlsx\")\n",
    "        event_df[\"Titles\"] = event_df[\"عنوان\"]\n",
    "\n",
    "        return event_df\n",
    "\n",
    "    def merged_all_df(\n",
    "        self,\n",
    "        df_title: pd.DataFrame,\n",
    "        df_location: pd.DataFrame,\n",
    "        df_date: pd.DataFrame,\n",
    "        df_interaction: pd.DataFrame,\n",
    "        df_buy_history: pd.DataFrame,\n",
    "        event_df: pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\"merged all df to concat all titles under each other\n",
    "\n",
    "        Args:\n",
    "            df_title (pd.DataFrame): df_title scrape from data_scrap func output\n",
    "            df_location (pd.DataFrame): df_location scrape from data_scrap func output\n",
    "            df_date (pd.DataFrame): df_date scrape from data_scrap func output\n",
    "            df_interaction (pd.DataFrame): df_interaction scrape from user_buy_interaction_from_api func output\n",
    "            df_buy_history (pd.DataFrame): df_buy_history scrape from user_buy_interaction_from_api func output\n",
    "\n",
    "        Returns:\n",
    "            merged df: Pandas DataFrame\n",
    "        \"\"\"\n",
    "        merge_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Titles\": df_title[\"Titles\"],\n",
    "                \"Location\": df_location[\"Titles\"],\n",
    "                \"Date\": df_date[\"Titles\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        merge_df = pd.concat(\n",
    "            [\n",
    "                merge_df[\"Titles\"],\n",
    "                df_interaction[\"بازدید\"],\n",
    "                df_buy_history[\"رویداد\"],\n",
    "                event_df[\"Titles\"],\n",
    "            ]\n",
    "        ).reset_index()\n",
    "\n",
    "        merge_df.columns = [\"index\", \"Titles\"]\n",
    "\n",
    "        return merge_df\n",
    "\n",
    "    def list_to_string(self, row):\n",
    "        return \" \".join(row)\n",
    "\n",
    "    def remove_excel(self, excel_list: list):\n",
    "        for i in excel_list:\n",
    "            os.remove(i)\n",
    "\n",
    "    def preprocessing_merged_df(self, merged_df: pd.DataFrame):\n",
    "        \"\"\"preprocessing merged_df data for use in model\n",
    "\n",
    "        Args:\n",
    "            merged_df (pd.DataFrame): merged_df pd from merged_all_df func output\n",
    "\n",
    "        Returns:\n",
    "            merged_df: Pandas DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        df_ohe = merged_df[\"Titles\"].str.split(\" \").reset_index().astype(\"str\")\n",
    "        df_ohe[\"Titles\"] = df_ohe[\"Titles\"].apply(self.list_to_string)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        merged_df[\"ohe\"] = le.fit_transform(df_ohe[\"Titles\"])\n",
    "\n",
    "        self.merged_df = merged_df\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    def vectorized_text(self, df_title: pd.DataFrame):\n",
    "        \"\"\"vectorized_text for merged Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "        Args:\n",
    "            df_title (pd.DataFrame): use df_title from data_scrap func output\n",
    "\n",
    "        Returns:\n",
    "            X : array of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "\n",
    "        vectorized = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "        X = vectorized.fit_transform(self.merged_df[\"Titles\"])\n",
    "\n",
    "        feature_names = vectorized.get_feature_names_out()\n",
    "        one_hot_df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "        dfs = pd.concat([df_title, one_hot_df], axis=1)\n",
    "        dfs.drop(columns=[\"Titles\"], inplace=True)\n",
    "\n",
    "        self.dfs = dfs\n",
    "        return dfs\n",
    "\n",
    "    def creat_X(self, interaction_df):\n",
    "        \"\"\"Compressed Sparse Row matrix.\n",
    "\n",
    "        Args:\n",
    "            iteraction_df (_type_): use preprocessing_interaction func output\n",
    "\n",
    "        Returns:\n",
    "            sparse matrix of type '<class 'numpy.float64'>\n",
    "        \"\"\"\n",
    "\n",
    "        M = interaction_df[\"userId\"].nunique()\n",
    "        N = interaction_df[\"بازدید\"].nunique()\n",
    "\n",
    "        user_mapper = dict(zip(np.unique(interaction_df[\"userId\"]), list(range(M))))\n",
    "        item_mapper = dict(zip(np.unique(interaction_df[\"بازدید\"]), list(range(N))))\n",
    "\n",
    "        user_inv_mapper = dict(zip(list(range(M)), np.unique(interaction_df[\"userId\"])))\n",
    "        item_inv_mapper = dict(zip(list(range(N)), np.unique(interaction_df[\"بازدید\"])))\n",
    "\n",
    "        user_index = [user_mapper[i] for i in interaction_df[\"userId\"]]\n",
    "        item_indx = [item_mapper[i] for i in interaction_df[\"بازدید\"]]\n",
    "\n",
    "        X = csr_matrix(\n",
    "            (interaction_df[\"زمان تعامل(تانیه)\"], (user_index, item_indx)), shape=(M, N)\n",
    "        )\n",
    "\n",
    "        return X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper\n",
    "\n",
    "    def cosine_similioraty(\n",
    "        self,\n",
    "        dfs: pd.DataFrame,\n",
    "        event_df: pd.DataFrame,\n",
    "        interaction_df: pd.DataFrame,\n",
    "        idx: str,\n",
    "        n_recommendations: int = 1,\n",
    "    ):\n",
    "        \"\"\"Compute cosine similarity between samples in X and Y.\n",
    "\n",
    "        Cosine similarity, or the cosine kernel, computes similarity as the normalized dot product of X and Y:\n",
    "\n",
    "                Args:\n",
    "                    dfs (pd.DataFrame): use vectorized_text func outputs\n",
    "                    merged_df (pd.DataFrame): use preprocessing_merged_df func outputs\n",
    "                    interaction_df (pd.DataFrame): use preprocessing_interaction func output\n",
    "                    idx (str): idx of user interation and buy\n",
    "                    n_recommendations (int, optional): Number of outgoing recommenders. Defaults to 1.\n",
    "\n",
    "                Returns:\n",
    "                    list: user best recommenders\n",
    "        \"\"\"\n",
    "        cosine_sim = cosine_similarity(dfs, dfs)\n",
    "        iter_idx = dict(zip(event_df[\"Titles\"].unique(), list(event_df.index)))\n",
    "        idx = iter_idx[idx]\n",
    "        n_recommendations = n_recommendations\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1 : (n_recommendations + 1)]\n",
    "        similar_item = [i[0] for i in sim_scores]\n",
    "        recomended = event_df[\"Titles\"].iloc[similar_item]\n",
    "        recomended = recomended.to_list()\n",
    "\n",
    "        return recomended\n",
    "\n",
    "    def recomender_users(\n",
    "        self,\n",
    "        interaction_df: pd.DataFrame,\n",
    "        dfs: pd.DataFrame,\n",
    "        event_df: pd.DataFrame,\n",
    "        n_recommendations=1,\n",
    "    ):\n",
    "        \"\"\"use interaction_df ,dfs,merged_df to recommend best for each user\n",
    "\n",
    "        Args:\n",
    "            interaction_df (pd.DataFrame): use preprocessing_interaction func output\n",
    "            merged_df (pd.DataFrame): use preprocessing_merged_df func outputs\n",
    "            dfs (pd.DataFrame): use vectorized_text func outputs\n",
    "\n",
    "        Returns:\n",
    "            dict: user(phone number) recommender\n",
    "        \"\"\"\n",
    "        users_phone = interaction_df[\"شماره موبایل\"].unique()\n",
    "        user_iter = {}\n",
    "        for i in users_phone:\n",
    "            user_it = (\n",
    "                interaction_df[interaction_df[\"شماره موبایل\"] == i][\n",
    "                    [\"زمان تعامل(تانیه)\", \"بازدید\"]\n",
    "                ]\n",
    "                .max()\n",
    "                .reset_index()\n",
    "                .T\n",
    "            )\n",
    "            user_it.columns = [\"زمان تعامل(تانیه)\", \"بازدید\"]\n",
    "            user_it.drop(index=\"index\", inplace=True)\n",
    "            user_it[\"بازدید\"]\n",
    "            idx = user_it[\"بازدید\"].to_list()[0]\n",
    "            phone = str(i)\n",
    "            phone = phone[:-2]\n",
    "            iters = self.cosine_similioraty(\n",
    "                dfs,\n",
    "                event_df,\n",
    "                interaction_df,\n",
    "                idx=idx,\n",
    "                n_recommendations=n_recommendations,\n",
    "            )\n",
    "            user_dict = {phone: iters}\n",
    "            user_iter.update(user_dict)\n",
    "\n",
    "        temp = []\n",
    "        res = dict()\n",
    "\n",
    "        for key, val in user_iter.items():\n",
    "            if val not in res.values():\n",
    "                res[key] = val\n",
    "\n",
    "        return user_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomender = Recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = recomender.interaction_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_history = recomender.buy_auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title, df_location, df_date = recomender.data_scrap(\"https://www.6234.ir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction, buy_history = recomender.user_buy_interaction_from_api(\n",
    "#     buy_api=\"https://6234.ir/api/ticket?token=aiapiqazxcvbnm1403&ofDate=1402/08/20&toDate=1403/12/29\",\n",
    "#     iter_api=\"https://6234.ir/api/log?token=aiapiqazxcvbnm1403&ofDate=1403/02/01&toDate=1403/03/29\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = recomender.event_api(\"https://6234.ir/api/event?token=aiapiqazxcvbnm1403\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = recomender.preprocessing_interaction(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = recomender.merged_all_df(\n",
    "    df_title, df_location, df_date, interaction, buy_history, event_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = recomender.preprocessing_merged_df(merged_df)\n",
    "dfs = recomender.vectorized_text(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper = recomender.creat_X(\n",
    "    interaction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': ['نمایش کمدی ژیلت',\n",
       "  'کنسرت هانیبال صلح و دوستی',\n",
       "  'کنسرت امید حاجیلی',\n",
       "  'قوانین و مقررات'],\n",
       " '9195920275': ['کنسرت نمایش کلنل',\n",
       "  'پارک امیرگان ( Test )',\n",
       "  'کنسرت تست ( با انتخاب صندلی )',\n",
       "  'نمایشگاه ترکیه']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomender.recomender_users(interaction, dfs, merged_df, n_recommendations=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recomender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recomender\u001b[38;5;241m.\u001b[39mremove_excel([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisitor.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recomender' is not defined"
     ]
    }
   ],
   "source": [
    "recomender.remove_excel([\"event.xlsx\", \"log.xlsx\", \"visitor.xlsx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_ranges(start_date, end_date):\n",
    "    date_ranges = []\n",
    "    current_start_date = start_date\n",
    "    while current_start_date < end_date:\n",
    "        current_end_date = current_start_date + timedelta(days=60)\n",
    "        if current_end_date > end_date:\n",
    "            current_end_date = end_date\n",
    "        date_ranges.append((current_start_date, current_end_date))\n",
    "        current_start_date = current_end_date\n",
    "    return date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تعداد ماه‌های بین  و : 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jdatetime\n",
    "\n",
    "\n",
    "def calculate_month_difference(start_date, end_date):\n",
    "    # محاسبه اختلاف سال‌ها و ماه‌ها\n",
    "    year_diff = end_date.year - start_date.year\n",
    "    month_diff = end_date.month - start_date.month\n",
    "\n",
    "    # تعداد کل ماه‌ها\n",
    "    total_months = year_diff * 12 + month_diff\n",
    "\n",
    "    return total_months\n",
    "\n",
    "\n",
    "# تاریخ‌های شمسی\n",
    "start_date_jalali = jdatetime.date(1401, 10, 1)\n",
    "end_date_jalali = jdatetime.date(1403, 3, 11)\n",
    "\n",
    "# محاسبه تعداد ماه‌ها\n",
    "month_difference = calculate_month_difference(start_date_jalali, end_date_jalali)\n",
    "\n",
    "print(f\"تعداد ماه‌های بین {start_date_jalali} و {end_date_jalali}: {month_difference}\")\n",
    "month_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_from_api(start_date, end_date):\n",
    "    start_date = start_date.strftime(\"%Y/%m/%d\")\n",
    "    end_date = end_date.strftime(\"%Y/%m/%d\")\n",
    "    url = f\"https://6234.ir/api/log?token=aiapiqazxcvbnm1403&ofDate={start_date}&toDate={end_date}\"\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_jalali = jdatetime.datetime.strptime(\n",
    "    jdatetime.date(1402, 1, 1).strftime(\"%Y/%m/%d\"), \"%Y/%m/%d\"\n",
    ").date()\n",
    "end_date_jalali = jdatetime.datetime.strptime(\n",
    "    jdatetime.datetime.now().strftime(\"%Y/%m/%d\"), \"%Y/%m/%d\"\n",
    ").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(jdatetime.date(1402, 1, 1), jdatetime.date(1402, 2, 30)),\n",
       " (jdatetime.date(1402, 2, 30), jdatetime.date(1402, 4, 28)),\n",
       " (jdatetime.date(1402, 4, 28), jdatetime.date(1402, 6, 26)),\n",
       " (jdatetime.date(1402, 6, 26), jdatetime.date(1402, 8, 25)),\n",
       " (jdatetime.date(1402, 8, 25), jdatetime.date(1402, 10, 25)),\n",
       " (jdatetime.date(1402, 10, 25), jdatetime.date(1402, 12, 25)),\n",
       " (jdatetime.date(1402, 12, 25), jdatetime.date(1403, 2, 25)),\n",
       " (jdatetime.date(1403, 2, 25), jdatetime.date(1403, 4, 1))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_ranges = generate_date_ranges(start_date_jalali, end_date_jalali)\n",
    "date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start, end in date_ranges:\n",
    "    urllib.request.urlretrieve(\n",
    "        fetch_data_from_api(start, end), f\"log{start.month}.xlsx\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soheil\\AppData\\Local\\Temp\\ipykernel_7696\\54046392.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat(df_api.values(), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_api = {}\n",
    "for start, end in date_ranges:\n",
    "    month = start.month\n",
    "    df = pd.read_excel(f\"log{month}.xlsx\")\n",
    "\n",
    "    if month in df_api:\n",
    "        # اگر ماه از قبل در دیکشنری موجود است، داده‌ها را به هم بچسبانید\n",
    "        df_api[month] = pd.concat([df_api[month], df], ignore_index=True)\n",
    "    else:\n",
    "        df_api[month] = df\n",
    "\n",
    "# ترکیب تمام DataFrame‌ها به یک DataFrame واحد\n",
    "combined_df = pd.concat(df_api.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>نام و نام خانوادگی</th>\n",
       "      <th>شماره موبایل</th>\n",
       "      <th>بازدید</th>\n",
       "      <th>زمان تعامل(تانیه)</th>\n",
       "      <th>آی پی</th>\n",
       "      <th>تاریخ</th>\n",
       "      <th>تگ ها</th>\n",
       "      <th>توضیحات</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>65.154.226.167</td>\n",
       "      <td>1403/03/31 21:51:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>151.240.244.36</td>\n",
       "      <td>1403/03/31 21:08:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>139.171.105.253</td>\n",
       "      <td>1403/03/31 21:00:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>151.240.244.128</td>\n",
       "      <td>1403/03/31 20:08:37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>151.240.244.128</td>\n",
       "      <td>1403/03/31 20:08:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51142</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.129.210.219</td>\n",
       "      <td>1402/12/25 01:12:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51143</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.129.210.219</td>\n",
       "      <td>1402/12/25 01:12:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51144</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>37.129.210.219</td>\n",
       "      <td>1402/12/25 01:12:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51145</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>21.018</td>\n",
       "      <td>37.129.210.219</td>\n",
       "      <td>1402/12/25 01:11:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51146</th>\n",
       "      <td>ناشناس</td>\n",
       "      <td>NaN</td>\n",
       "      <td>صفحه اصلی</td>\n",
       "      <td>0.000</td>\n",
       "      <td>42.236.12.241</td>\n",
       "      <td>1402/12/25 00:14:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      نام و نام خانوادگی  شماره موبایل     بازدید  زمان تعامل(تانیه)  \\\n",
       "0                 ناشناس           NaN  صفحه اصلی              0.000   \n",
       "1                 ناشناس           NaN  صفحه اصلی              0.000   \n",
       "2                 ناشناس           NaN  صفحه اصلی              0.000   \n",
       "3                 ناشناس           NaN  صفحه اصلی              0.000   \n",
       "4                 ناشناس           NaN  صفحه اصلی              0.000   \n",
       "...                  ...           ...        ...                ...   \n",
       "51142             ناشناس           NaN  صفحه اصلی              0.000   \n",
       "51143             ناشناس           NaN  صفحه اصلی              0.000   \n",
       "51144             ناشناس           NaN  صفحه اصلی              0.000   \n",
       "51145             ناشناس           NaN  صفحه اصلی             21.018   \n",
       "51146             ناشناس           NaN  صفحه اصلی              0.000   \n",
       "\n",
       "                 آی پی                تاریخ تگ ها توضیحات  \n",
       "0       65.154.226.167  1403/03/31 21:51:30   NaN     NaN  \n",
       "1       151.240.244.36  1403/03/31 21:08:51   NaN     NaN  \n",
       "2      139.171.105.253  1403/03/31 21:00:25   NaN     NaN  \n",
       "3      151.240.244.128  1403/03/31 20:08:37   NaN     NaN  \n",
       "4      151.240.244.128  1403/03/31 20:08:09   NaN     NaN  \n",
       "...                ...                  ...   ...     ...  \n",
       "51142   37.129.210.219  1402/12/25 01:12:13   NaN     NaN  \n",
       "51143   37.129.210.219  1402/12/25 01:12:13   NaN     NaN  \n",
       "51144   37.129.210.219  1402/12/25 01:12:04   NaN     NaN  \n",
       "51145   37.129.210.219  1402/12/25 01:11:59   NaN     NaN  \n",
       "51146    42.236.12.241  1402/12/25 00:14:08   NaN     NaN  \n",
       "\n",
       "[51147 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://6234.ir/api/log?token=aiapiqazxcvbnm1403&ofDate=1403/02/25&toDate=1403/04/01'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_data_from_api(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(date_ranges)):\n",
    "    urllib.request.urlretrieve(\n",
    "        url,\n",
    "        \"visitor.xlsx\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(jdatetime.date(1403, 2, 25), jdatetime.date(1403, 4, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(month_difference):\n",
    "    df_dict = {}\n",
    "    df_dict.update(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1402-01-01 1402-02-30\n",
      "1402-02-30 1402-04-28\n",
      "1402-04-28 1402-06-26\n",
      "1402-06-26 1402-08-25\n",
      "1402-08-25 1402-10-25\n",
      "1402-10-25 1402-12-25\n",
      "1402-12-25 1403-02-25\n",
      "1403-02-25 1403-03-31\n"
     ]
    }
   ],
   "source": [
    "for start, end in date_ranges:\n",
    "    print(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jdatetime.date(1403, 2, 25)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jdatetime.date(1403, 3, 31)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['none', 9195920275.0], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction[\"شماره موبایل\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('log1.xlsx', <http.client.HTTPMessage at 0x146be5d4fd0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\n",
    "    \"https://6234.ir/api/log?token=aiapiqazxcvbnm1403&ofDate=1403/02/01&toDate=1403/03/29\",\n",
    "    \"log1.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(month_difference):\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://6234.ir/api/log?token=aiapiqazxcvbnm1403&ofDate=1403/02/01&toDate=1403/03/29\",\n",
    "        f\"log{i}.xlsx\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
