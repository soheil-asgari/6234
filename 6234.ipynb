{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting information about the events on the site from the api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self):\n",
    "        self.url = None\n",
    "        self.df_title = None\n",
    "        self.df_location = None\n",
    "        self.df_date = None\n",
    "        self.buy_history = None\n",
    "        self.iter_history = None\n",
    "        self.interaction = None\n",
    "        self.merged_df = None\n",
    "        self.dfs = None\n",
    "        self.recommender = None\n",
    "\n",
    "    def data_scrap(self, url: str):\n",
    "        \"\"\"use site url to scrap necessary data\n",
    "\n",
    "        Args:\n",
    "            url (str): site address\n",
    "\n",
    "        \"\"\"\n",
    "        url = url\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            h3_tags_title = soup.find_all(\"h3\", class_=\"blog_post_title my-2\")\n",
    "            h3_tags_location = soup.find_all(\"div\", class_=\"blog_post_title my-2\")\n",
    "            h3_tags_date = soup.find_all(\"div\", class_=\"theater-date my-2\")\n",
    "\n",
    "            titles = []\n",
    "            location = []\n",
    "            date = []\n",
    "\n",
    "            for title in h3_tags_title:\n",
    "                if title.text.strip():\n",
    "                    titles.append(title.text.strip())\n",
    "\n",
    "            self.df_title = pd.DataFrame({\"Titles\": titles})\n",
    "            df_title = self.df_title\n",
    "\n",
    "            for loc in h3_tags_location:\n",
    "                if loc.text.strip():\n",
    "                    location.append(loc.text.strip())\n",
    "\n",
    "            self.df_location = pd.DataFrame({\"Titles\": location})\n",
    "            df_location = self.df_location\n",
    "\n",
    "            for dt in h3_tags_date:\n",
    "                if dt.text.strip():\n",
    "                    date.append(dt.text.strip())\n",
    "\n",
    "            self.df_date = pd.DataFrame({\"Titles\": date})\n",
    "            df_date = self.df_date\n",
    "\n",
    "            return df_title, df_location, df_date\n",
    "\n",
    "    def user_buy_interaction_from_api(self, buy_api: str, iter_api: str):\n",
    "        \"\"\"use api to scrap buy and interaction users\n",
    "\n",
    "        Args:\n",
    "            buy_api (str): api to scrape user buy history\n",
    "            iter_api (str): api to scrape user iter history\n",
    "        \"\"\"\n",
    "        buy_link = buy_api\n",
    "        iter_link = iter_api\n",
    "\n",
    "        urllib.request.urlretrieve(iter_link, \"log.xlsx\")\n",
    "        self.iter_history = pd.read_excel(\"log.xlsx\")\n",
    "        iter_history = pd.read_excel(\"log.xlsx\")\n",
    "\n",
    "        urllib.request.urlretrieve(buy_link, \"visitor.xlsx\")\n",
    "        self.buy_history = pd.read_excel(\"visitor.xlsx\")\n",
    "        buy_history = pd.read_excel(\"visitor.xlsx\")\n",
    "\n",
    "        return iter_history, buy_history\n",
    "\n",
    "    def preprocessing_interaction(self, interaction_df: pd.DataFrame):\n",
    "        \"\"\"preprocessing interaction data for use in model\n",
    "\n",
    "        Args:\n",
    "            interaction_df (pd.DataFrame): interaction pd from user_buy_interaction_from_api func\n",
    "\n",
    "        Returns:\n",
    "            interaction_df (pd.DataFrame): interaction_df\n",
    "        \"\"\"\n",
    "        interaction_df[\"بازدید\"] = interaction_df[\"بازدید\"].fillna(\"ffill\")\n",
    "        interaction_df[\"نام و نام خانوادگی\"] = interaction_df[\n",
    "            \"نام و نام خانوادگی\"\n",
    "        ].fillna(\"none\")\n",
    "        interaction_df[\"شماره موبایل\"] = interaction_df[\"شماره موبایل\"].fillna(\"none\")\n",
    "        interaction_df = interaction_df[interaction_df[\"بازدید\"] != \"صفحه اصلی\"]\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        interaction_df[\"userId\"] = le.fit_transform(\n",
    "            interaction_df[\"نام و نام خانوادگی\"]\n",
    "        )\n",
    "\n",
    "        return interaction_df\n",
    "\n",
    "    def merged_all_df(\n",
    "        self,\n",
    "        df_title: pd.DataFrame,\n",
    "        df_location: pd.DataFrame,\n",
    "        df_date: pd.DataFrame,\n",
    "        df_interaction: pd.DataFrame,\n",
    "        df_buy_history: pd.DataFrame,\n",
    "    ):\n",
    "        \"\"\"merged all df to concat all titles under each other\n",
    "\n",
    "        Args:\n",
    "            df_title (pd.DataFrame): df_title scrape from data_scrap func output\n",
    "            df_location (pd.DataFrame): df_location scrape from data_scrap func output\n",
    "            df_date (pd.DataFrame): df_date scrape from data_scrap func output\n",
    "            df_interaction (pd.DataFrame): df_interaction scrape from user_buy_interaction_from_api func output\n",
    "            df_buy_history (pd.DataFrame): df_buy_history scrape from user_buy_interaction_from_api func output\n",
    "\n",
    "        Returns:\n",
    "            merged df: Pandas DataFrame\n",
    "        \"\"\"\n",
    "        merge_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Titles\": df_title[\"Titles\"],\n",
    "                \"Location\": df_location[\"Titles\"],\n",
    "                \"Date\": df_date[\"Titles\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        merge_df = pd.concat(\n",
    "            [\n",
    "                merge_df[\"Titles\"],\n",
    "                df_interaction[\"بازدید\"],\n",
    "                df_buy_history[\"رویداد\"],\n",
    "            ]\n",
    "        ).reset_index()\n",
    "\n",
    "        merge_df.columns = [\"index\", \"Titles\"]\n",
    "\n",
    "        return merge_df\n",
    "\n",
    "    def list_to_string(self, row):\n",
    "        return \" \".join(row)\n",
    "\n",
    "    def preprocessing_merged_df(self, merged_df: pd.DataFrame):\n",
    "        \"\"\"preprocessing merged_df data for use in model\n",
    "\n",
    "        Args:\n",
    "            merged_df (pd.DataFrame): merged_df pd from merged_all_df func output\n",
    "\n",
    "        Returns:\n",
    "            merged_df: Pandas DataFrame\n",
    "        \"\"\"\n",
    "\n",
    "        df_ohe = merged_df[\"Titles\"].str.split(\" \").reset_index().astype(\"str\")\n",
    "        df_ohe[\"Titles\"] = df_ohe[\"Titles\"].apply(self.list_to_string)\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        merged_df[\"ohe\"] = le.fit_transform(df_ohe[\"Titles\"])\n",
    "\n",
    "        self.merged_df = merged_df\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    def vectorized_text(self, df_title: pd.DataFrame):\n",
    "        \"\"\"vectorized_text for merged Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "        Args:\n",
    "            df_title (pd.DataFrame): use df_title from data_scrap func output\n",
    "\n",
    "        Returns:\n",
    "            X : array of shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "\n",
    "        vectorized = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "        X = vectorized.fit_transform(self.merged_df[\"Titles\"])\n",
    "\n",
    "        feature_names = vectorized.get_feature_names_out()\n",
    "        one_hot_df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "        dfs = pd.concat([df_title, one_hot_df], axis=1)\n",
    "        dfs.drop(columns=[\"Titles\"], inplace=True)\n",
    "\n",
    "        self.dfs = dfs\n",
    "        return dfs\n",
    "\n",
    "    def creat_X(self, interaction_df):\n",
    "        \"\"\"Compressed Sparse Row matrix.\n",
    "\n",
    "        Args:\n",
    "            iteraction_df (_type_): use preprocessing_interaction func output\n",
    "\n",
    "        Returns:\n",
    "            sparse matrix of type '<class 'numpy.float64'>\n",
    "        \"\"\"\n",
    "\n",
    "        M = interaction_df[\"userId\"].nunique()\n",
    "        N = interaction_df[\"بازدید\"].nunique()\n",
    "\n",
    "        user_mapper = dict(zip(np.unique(interaction_df[\"userId\"]), list(range(M))))\n",
    "        item_mapper = dict(zip(np.unique(interaction_df[\"بازدید\"]), list(range(N))))\n",
    "\n",
    "        user_inv_mapper = dict(zip(list(range(M)), np.unique(interaction_df[\"userId\"])))\n",
    "        item_inv_mapper = dict(zip(list(range(N)), np.unique(interaction_df[\"بازدید\"])))\n",
    "\n",
    "        user_index = [user_mapper[i] for i in interaction_df[\"userId\"]]\n",
    "        item_indx = [item_mapper[i] for i in interaction_df[\"بازدید\"]]\n",
    "\n",
    "        X = csr_matrix(\n",
    "            (interaction_df[\"زمان تعامل(تانیه)\"], (user_index, item_indx)), shape=(M, N)\n",
    "        )\n",
    "\n",
    "        return X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper\n",
    "\n",
    "    def cosine_similioraty(\n",
    "        dfs: pd.DataFrame,\n",
    "        merged_df: pd.DataFrame,\n",
    "        interaction_df: pd.DataFrame,\n",
    "        idx: str,\n",
    "        n_recommendations: int = 1,\n",
    "    ):\n",
    "        \"\"\"Compute cosine similarity between samples in X and Y.\n",
    "\n",
    "        Cosine similarity, or the cosine kernel, computes similarity as the normalized dot product of X and Y:\n",
    "\n",
    "                Args:\n",
    "                    dfs (pd.DataFrame): use vectorized_text func outputs\n",
    "                    merged_df (pd.DataFrame): use preprocessing_merged_df func outputs\n",
    "                    interaction_df (pd.DataFrame): use preprocessing_interaction func output\n",
    "                    idx (str): idx of user interation and buy\n",
    "                    n_recommendations (int, optional): Number of outgoing recommenders. Defaults to 1.\n",
    "\n",
    "                Returns:\n",
    "                    list: user best recommenders\n",
    "        \"\"\"\n",
    "        cosine_sim = cosine_similarity(dfs, dfs)\n",
    "        iter_idx = dict(zip(merged_df[\"Titles\"].unique(), list(interaction_df.index)))\n",
    "        idx = iter_idx[idx]\n",
    "        n_recommendations = n_recommendations\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1 : (n_recommendations + 1)]\n",
    "        similar_item = [i[0] for i in sim_scores]\n",
    "        recomended = merged_df[\"Titles\"].iloc[similar_item]\n",
    "        recomended = recomended.to_list()\n",
    "\n",
    "        return recomended\n",
    "\n",
    "    def recomender_users(\n",
    "        self, interaction_df: pd.DataFrame, dfs: pd.DataFrame, merged_df: pd.DataFrame\n",
    "    ):\n",
    "        \"\"\"use interaction_df ,dfs,merged_df to recommend best for each user\n",
    "\n",
    "        Args:\n",
    "            interaction_df (pd.DataFrame): use preprocessing_interaction func output\n",
    "            merged_df (pd.DataFrame): use preprocessing_merged_df func outputs\n",
    "            dfs (pd.DataFrame): use vectorized_text func outputs\n",
    "\n",
    "        Returns:\n",
    "            dict: user(phone number) recommender\n",
    "        \"\"\"\n",
    "        users_phone = interaction_df[\"شماره موبایل\"].unique()\n",
    "        user_iter = {}\n",
    "        for i in users_phone:\n",
    "            user_it = (\n",
    "                interaction_df[interaction_df[\"شماره موبایل\"] == i][\n",
    "                    [\"زمان تعامل(تانیه)\", \"بازدید\"]\n",
    "                ]\n",
    "                .max()\n",
    "                .reset_index()\n",
    "                .T\n",
    "            )\n",
    "            user_it.columns = [\"زمان تعامل(تانیه)\", \"بازدید\"]\n",
    "            user_it.drop(index=\"index\", inplace=True)\n",
    "            user_it[\"بازدید\"]\n",
    "            idx = user_it[\"بازدید\"].to_list()[0]\n",
    "            names = i\n",
    "            iters = self.cosine_similioraty(dfs, merged_df, interaction_df, idx=idx)\n",
    "            user_dict = {names: iters}\n",
    "            user_iter.update(user_dict)\n",
    "        return user_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomender = Recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title, df_location, df_date = recomender.data_scrap(\"https://www.6234.ir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction, buy_history = recomender.user_buy_interaction_from_api(\n",
    "    buy_api=\"https://6234.ir/api/ticket?token=apiqazxcvbnm&ofDate=1402/08/20&toDate=1402/12/29\",\n",
    "    iter_api=\"https://6234.ir/api/log?token=apiqazxcvbnm&ofDate=1402/08/20&toDate=1402/12/29\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction = recomender.preprocessing_interaction(interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = recomender.merged_all_df(\n",
    "    df_title, df_location, df_date, interaction, buy_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = recomender.preprocessing_merged_df(merged_df)\n",
    "dfs = recomender.vectorized_text(df_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, user_mapper, item_mapper, user_inv_mapper, item_inv_mapper = recomender.creat_X(\n",
    "    interaction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Recommender.cosine_similioraty() got multiple values for argument 'idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m idx \u001b[38;5;241m=\u001b[39m user_it[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mبازدید\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m names \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m---> 15\u001b[0m iters \u001b[38;5;241m=\u001b[39m recomender\u001b[38;5;241m.\u001b[39mcosine_similioraty(dfs, merged_df, interaction, idx\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m     16\u001b[0m user_dict \u001b[38;5;241m=\u001b[39m {names: iters}\n\u001b[0;32m     17\u001b[0m user_iter\u001b[38;5;241m.\u001b[39mupdate(user_dict)\n",
      "\u001b[1;31mTypeError\u001b[0m: Recommender.cosine_similioraty() got multiple values for argument 'idx'"
     ]
    }
   ],
   "source": [
    "users_phone = interaction[\"شماره موبایل\"].unique()\n",
    "user_iter = {}\n",
    "for i in users_phone:\n",
    "    user_it = (\n",
    "        interaction[interaction[\"شماره موبایل\"] == i][[\"زمان تعامل(تانیه)\", \"بازدید\"]]\n",
    "        .max()\n",
    "        .reset_index()\n",
    "        .T\n",
    "    )\n",
    "    user_it.columns = [\"زمان تعامل(تانیه)\", \"بازدید\"]\n",
    "    user_it.drop(index=\"index\", inplace=True)\n",
    "    user_it[\"بازدید\"]\n",
    "    idx = user_it[\"بازدید\"].to_list()[0]\n",
    "    names = i\n",
    "    iters = recomender.cosine_similioraty(dfs, merged_df, interaction, idx=idx)\n",
    "    user_dict = {names: iters}\n",
    "    user_iter.update(user_dict)\n",
    "user_iter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
